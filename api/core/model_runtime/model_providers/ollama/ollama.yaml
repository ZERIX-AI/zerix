provider: ollama
label:
  en_US: Ollama
icon_large:
  en_US: icon_l_en.svg
icon_small:
  en_US: icon_s_en.svg
background: "#F9FAFB"
help:
  title:
    en_US: How to integrate with Ollama
  url:
    en_US: https://docs.zerix.ai/tutorials/model-configuration/ollama
supported_model_types:
  - llm
  - text-embedding
configurate_methods:
  - customizable-model
model_credential_schema:
  model:
    label:
      en_US: Model Name
    placeholder:
      en_US: Enter your model name
  credential_form_schemas:
    - variable: base_url
      label:
        en_US: Base URL
      type: text-input
      required: true
      placeholder:
        en_US: Base url of Ollama server, e.g. http://192.168.1.100:11434
    - variable: mode
      show_on:
        - variable: __model_type
          value: llm
      label:
        en_US: Completion mode
      type: select
      required: true
      default: chat
      placeholder:
        en_US: Select completion mode
      options:
        - value: completion
          label:
            en_US: Completion
        - value: chat
          label:
            en_US: Chat
    - variable: context_size
      label:
        en_US: Model context size
      required: true
      type: text-input
      default: '4096'
      placeholder:
        en_US: Enter your Model context size
    - variable: max_tokens
      label:
        en_US: Upper bound for max tokens
      show_on:
        - variable: __model_type
          value: llm
      default: '4096'
      type: text-input
      required: true
    - variable: vision_support
      label:
        en_US: Vision support
      show_on:
        - variable: __model_type
          value: llm
      default: 'false'
      type: radio
      required: false
      options:
        - value: 'true'
          label:
            en_US: 'Yes'
        - value: 'false'
          label:
            en_US: 'No'
